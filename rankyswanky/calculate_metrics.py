from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
import os
import pydantic

AZURE_ENDPOINT: str = "https://gf-oai-gwcml-s-swno.openai.azure.com/"
AZURE_OPENAI_API_KEY: str = os.getenv("OPENAI_KEY")
AZURE_OPENAI_API_VERSION: str = "2024-10-21"
AZURE_DEPLOYMENT_EMBEDDINGS: str = "text-embedding-ada-002"
SYSTEM_PROMPT: str = """
You are an expert evaluator of search results with a deep understanding of many various topics.
You should rank the relevance by giving star ratings from 1 to 5, where 1 is not relevant at all and 5 is highly relevant.

5 means that the context is perfect and a full answer to the question can be generated by using this context.
4 means that the context is very relevant and can be used to generate a good answer to the question, but it may not cover all aspects of the question.
3 means that the context is relevant, but it may not provide enough information to generate a complete answer to the question.
2 means that the context is somewhat relevant, but it does not provide enough information to generate a good answer to the question.
1 means that the context is completely irrelevant to the question and does not provide any useful information for the question.

This is the question:
{question}

This is the context:
{context}

How relevant is the context to the question?
"""

class EvaluationResult(pydantic.BaseModel):
    """Model to hold the evaluation result."""

    relevance_score_1_to_5: int
    """Relevance score from 1 to 5."""


class RelevanceEvaluator:
    def __init__(self):
        self._embeddings_client = AzureOpenAIEmbeddings(
            azure_deployment=AZURE_DEPLOYMENT_EMBEDDINGS,
            azure_endpoint=AZURE_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            openai_api_version=AZURE_OPENAI_API_VERSION,
            max_retries=10,
            timeout=60,
        )

        self._open_chat_llm = AzureChatOpenAI(
            azure_endpoint=AZURE_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            azure_deployment="gpt-4o",
            api_version=AZURE_OPENAI_API_VERSION,
        )

        # self._open_chat_llm.bind_tools([EvaluationResult])


    def get_relevance_score(self, question: str, context: str) -> int:
        """Get the relevance score of the context to the question using an LLM."""
        evaluation_result: EvaluationResult = self._open_chat_llm.with_structured_output(EvaluationResult).invoke(
            SYSTEM_PROMPT.format(question=question, context=context),
        )
        return evaluation_result.relevance_score_1_to_5


if __name__ == "__main__":
    evaluator = RelevanceEvaluator()
    # Example usage
    question = "What is the capital of France?"
    context = "The capital of France is Paris."
    score = evaluator.get_relevance_score(question, context)
    print(
        f"Relevance score for the question '{question}' with context '{context}': {score}"
    )

    not_relevant_context = "The capital of Germany is Berlin."
    not_relevant_score = evaluator.get_relevance_score(question, not_relevant_context)
    print(
        f"Relevance score for the question '{question}' with context '{not_relevant_context}': {not_relevant_score}"
    )